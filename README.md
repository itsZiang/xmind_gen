# XMind Generator - T·∫°o Mind Map T·ª± ƒê·ªông

·ª®ng d·ª•ng AI t·∫°o mind map t·ª± ƒë·ªông t·ª´ vƒÉn b·∫£n, t√†i li·ªáu, gi·ªçng n√≥i v·ªõi kh·∫£ nƒÉng t√¨m ki·∫øm th√¥ng tin tr·ª±c tuy·∫øn v√† ch·ªânh s·ª≠a th√¥ng minh.

## T√≠nh nƒÉng ch√≠nh

### ƒêa d·∫°ng ngu·ªìn ƒë·∫ßu v√†o
- **T·ª´ t√†i li·ªáu**: PDF, DOCX, Markdown
- **T·ª´ gi·ªçng n√≥i**: Upload file audio ho·∫∑c thu √¢m tr·ª±c ti·∫øp
- **T√¨m ki·∫øm**: T·ª± ƒë·ªông t√¨m ki·∫øm th√¥ng tin t·ª´ internet
- **C∆° b·∫£n**: T·∫°o t·ª´ y√™u c·∫ßu ng∆∞·ªùi d√πng

### X·ª≠ l√Ω th√¥ng minh
- **Streaming real-time**: Xem qu√° tr√¨nh t·∫°o mind map tr·ª±c ti·∫øp
- **X·ª≠ l√Ω song song**: Chia nh·ªè vƒÉn b·∫£n l·ªõn ƒë·ªÉ x·ª≠ l√Ω hi·ªáu qu·∫£
- **Ch·ªânh s·ª≠a AI**: T·ª± ƒë·ªông c·∫≠p nh·∫≠t v√† b·ªï sung th√¥ng tin
- **T√≠ch h·ª£p t√¨m ki·∫øm**: Tavily Search API cho th√¥ng tin c·∫≠p nh·∫≠t

### Xu·∫•t ƒëa ƒë·ªãnh d·∫°ng
- **SVG**: H√¨nh ·∫£nh vector ch·∫•t l∆∞·ª£ng cao
- **XMind**: File t∆∞∆°ng th√≠ch v·ªõi ·ª©ng d·ª•ng XMind
- **Ch·ªânh s·ª≠a th·ªß c√¥ng**: Editor t√≠ch h·ª£p

## Ki·∫øn tr√∫c h·ªá th·ªëng

```
‚îú‚îÄ‚îÄ api/                   # FastAPI REST API
‚îÇ   ‚îî‚îÄ‚îÄ router.py          # API endpoints
‚îú‚îÄ‚îÄ agent/                 # LangGraph workflow engine
‚îÇ   ‚îú‚îÄ‚îÄ graph.py           # Workflow definitions
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ nodes.py       # Processing nodes
‚îÇ       ‚îú‚îÄ‚îÄ state.py       # State management
‚îÇ       ‚îî‚îÄ‚îÄ tools.py       # Utility functions
‚îú‚îÄ‚îÄ core/                  # Core services
‚îÇ   ‚îú‚îÄ‚îÄ audio_processing.py # Whisper integration
‚îÇ   ‚îú‚îÄ‚îÄ llm_handle.py      # LLM operations
‚îÇ   ‚îú‚îÄ‚îÄ llm_provider.py    # LLM configurations
‚îÇ   ‚îú‚îÄ‚îÄ prompt.py          # Prompt containing
‚îÇ   ‚îú‚îÄ‚îÄ tavily_search.py   # Search integration
‚îÇ   ‚îú‚îÄ‚îÄ text_processing.py # Document parsing
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # XMind/SVG conversion
‚îú‚îÄ‚îÄ ui.py                  # Streamlit interface
‚îî‚îÄ‚îÄ main.py                # FastAPI application
```

## C√†i ƒë·∫∑t

### Y√™u c·∫ßu h·ªá th·ªëng
- Python 3.8+
- Node.js (cho xmindmark CLI)
- FFmpeg (cho x·ª≠ l√Ω audio)

### 1. Clone repository
```bash
git clone https://github.com/itsZiang/xmind_gen.git
cd xmind-gen
```

### 2. C√†i ƒë·∫∑t Python dependencies
```bash
pip install -r requirements.txt
```

### 3. C√†i ƒë·∫∑t XMindMark CLI
```bash
npm install -g xmindmark
```

### 4. C·∫•u h√¨nh m√¥i tr∆∞·ªùng
T·∫°o file `.env`:
```env
# MISA LLM Configuration
API_KEY=your_misa_api_key
BASE_URL=your_misa_base_url

# Tavily Search API
TAVILY_API_KEY=your_tavily_api_key

# OpenAI (optional)
OPENAI_API_KEY=your_openai_api_key
```

### 5. T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
```bash
mkdir -p static/output_svg static/output_xmind static/output_audio logs
```

## Ch·∫°y ·ª©ng d·ª•ng

### Kh·ªüi ƒë·ªông API Server
```bash
bash run.sh (Ubuntu/MacOS)
run.bat (Windows) => T·ª± chuy·ªÉn run.sh th√†nh run.bat
```
API s·∫Ω ch·∫°y t·∫°i: `http://localhost:8000`
API Documentation: `http://localhost:8000/docs`

### Kh·ªüi ƒë·ªông Streamlit UI
```bash
streamlit run ui.py
```
Web interface: `http://localhost:8501`

## API Endpoints

### Audio Processing
```http
POST /api/generate-xmindmark-from-audio
Content-Type: multipart/form-data

- audio_file: File audio (WAV, MP3, M4A, OGG, FLAC, AAC)
- user_requirements: Y√™u c·∫ßu t·∫°o mind map
```

```http
POST /api/transcribe-audio
Content-Type: multipart/form-data

- audio_file: File audio c·∫ßn chuy·ªÉn ƒë·ªïi
```

### Document Processing
```http
POST /api/generate-xmindmark-from-docs
Content-Type: application/json

{
  "document_content": "N·ªôi dung t√†i li·ªáu",
  "user_requirements": "Y√™u c·∫ßu t·∫°o mind map",
  "stream": true
}
```

### General Generation
```http
POST /api/generate-xmindmark
Content-Type: application/json

{
  "user_requirements": "Y√™u c·∫ßu t·∫°o mind map",
  "enable_search": false,
  "stream": true
}
```

### Editing
```http
POST /api/edit-xmindmark
Content-Type: application/json

{
  "current_xmindmark": "N·ªôi dung hi·ªán t·∫°i",
  "edit_request": "Y√™u c·∫ßu ch·ªânh s·ª≠a",
  "enable_search": false,
  "original_user_requirements": ""
}
```

### Export
```http
POST /api/to-svg
Content-Type: application/json

{
  "content": "XMindMark content"
}
```

```http
POST /api/to-xmind
Content-Type: application/json

{
  "content": "XMindMark content"
}
```

## XMindMark Format

XMindMark l√† ƒë·ªãnh d·∫°ng vƒÉn b·∫£n ƒë∆°n gi·∫£n ƒë·ªÉ t·∫°o mind map:

```
Ti√™u ƒë·ªÅ ch√≠nh
- Nh√°nh ch√≠nh 1
  - Nh√°nh ph·ª• 1.1
    - Chi ti·∫øt 1.1.1
  - Nh√°nh ph·ª• 1.2
- Nh√°nh ch√≠nh 2
  - Nh√°nh ph·ª• 2.1
```

**Quy t·∫Øc:**
- D√≤ng ƒë·∫ßu: Ti√™u ƒë·ªÅ g·ªëc (kh√¥ng th·ª•t l·ªÅ)
- Level 1: `- N·ªôi dung` 
- Level 2: `  - N·ªôi dung` (2 spaces)
- Level 3: `    - N·ªôi dung` (4 spaces)
- M·ªói node ch·ªâ ch·ª©a t·ª´ kh√≥a/c·ª•m t·ª´ ng·∫Øn

## Workflow Engine (LangGraph)

### Lu·ªìng x·ª≠ l√Ω ch√≠nh:
1. **Input Processing**: X√°c ƒë·ªãnh lo·∫°i ƒë·∫ßu v√†o (text/audio/document)
2. **Content Analysis**: Ph√¢n t√≠ch v√† quy·∫øt ƒë·ªãnh c√≥ c·∫ßn chia nh·ªè kh√¥ng
3. **Parallel Processing**: X·ª≠ l√Ω song song c√°c chunk l·ªõn
4. **Information Enhancement**: T√¨m ki·∫øm b·ªï sung (n·∫øu enabled)
5. **Mind Map Generation**: T·∫°o XMindMark format
6. **Post-processing**: T·ªëi ∆∞u v√† format cu·ªëi c√πng

### Decision Points:
```python
def route_from_start(state: DocumentState):
    if state.get("audio_file"):
        return "process_audio"
    else:
        return "check_split"

def route_after_split(state: DocumentState):
    if state["need_split"]:
        return "split_chunks"
    elif state.get("search_mode", False):
        return "generate_with_search"
    elif state.get("audio_processed", False):
        return "generate_from_audio"
    else:
        return "generate_direct"
```

## Audio Processing

### Supported Formats
- **WAV**: Ch·∫•t l∆∞·ª£ng cao, kh√¥ng n√©n
- **MP3**: Ph·ªï bi·∫øn, n√©n c√≥ m·∫•t m√°t
- **M4A**: Apple format, ch·∫•t l∆∞·ª£ng t·ªët
- **OGG**: Open source, ch·∫•t l∆∞·ª£ng cao
- **FLAC**: Lossless compression
- **AAC**: Advanced Audio Codec

### Processing Pipeline
1. **Upload/Record**: Nh·∫≠n file audio ho·∫∑c thu √¢m
2. **Validation**: Ki·ªÉm tra format v√† k√≠ch th∆∞·ªõc (max 25MB)
3. **Transcription**: Whisper model chuy·ªÉn speech-to-text
4. **Translation**: D·ªãch sang ti·∫øng Vi·ªát (n·∫øu c·∫ßn)
5. **Mind Map Generation**: T·∫°o XMindMark t·ª´ vƒÉn b·∫£n

### Whisper Integration
```python
model = whisper.load_model("tiny")

audio = whisper.load_audio(file_path)
result = model.transcribe(audio, task="translate")
```

## üîç Search Integration

### Tavily Search API
- **Real-time Information**: T√¨m ki·∫øm th√¥ng tin m·ªõi nh·∫•t
- **Content Filtering**: L·ªçc n·ªôi dung ch·∫•t l∆∞·ª£ng cao
- **Deduplication**: Lo·∫°i b·ªè th√¥ng tin tr√πng l·∫∑p
- **Context Awareness**: K·∫øt h·ª£p v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i

### Search Flow
```python
def tavily_search(query: str) -> str:
    response = client.search(
        query=query,
        topic="general",
        max_results=5,
        include_raw_content="text"
    )
    return formatted_content
```

## Configuration

### LLM Providers
```python
# MISA LLM (Primary)
misa_llm = ChatOpenAI(
    model="misa-qwen3-235b",
    base_url=BASE_URL,
    api_key=API_KEY,
    max_tokens=8192,
    temperature=0.7
)

# OpenAI (Fallback)
llm = ChatOpenAI(model="gpt-4.1-mini")
```

### Processing Limits
- **Text splitting**: 100 characters threshold
- **Parallel processing**: Max 4 workers
- **Audio size**: 25MB limit
- **Search results**: Top 5 results
- **Token limits**: 8192 tokens per request

## Troubleshooting

### Common Issues

**1. Audio processing fails**
```bash
# Install FFmpeg
sudo apt-get install ffmpeg  # Ubuntu/Debian
brew install ffmpeg          # macOS
```

**2. XMindMark CLI not found**
```bash
# Reinstall xmindmark
npm uninstall -g xmindmark
npm install -g xmindmark
```

```
def generate_base_filename() -> str:
    now = datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M%S")
    return timestamp

After that, using generate_base_filename() instead of "xmindmark" in subprocess.run
```

**3. SVG generation errors**
- Ki·ªÉm tra XMindMark format
- Verify xmindmark CLI installation
- Check file permissions

**4. API connection issues**
- Verify environment variables
- Check API key validity
- Confirm base URLs

### Logging
Logs ƒë∆∞·ª£c l∆∞u t·∫°i: `logs/mindmap_YYYYMMDD.log`

```python
# Enable debug logging
logging.getLogger('agent.utils.nodes').setLevel(logging.DEBUG)
```

## Testing

### Manual Testing
1. **Basic Generation**: T·∫°o mind map t·ª´ text ƒë∆°n gi·∫£n
2. **Document Upload**: Test v·ªõi PDF/DOCX files
3. **Audio Processing**: Upload file WAV ng·∫Øn
4. **Search Integration**: Test v·ªõi y√™u c·∫ßu c·∫ßn th√¥ng tin m·ªõi
5. **Edit Functionality**: Ch·ªânh s·ª≠a mind map existing

### API Testing
```bash
# Test health endpoint
curl http://localhost:8000/health

# Test basic generation
curl -X POST "http://localhost:8000/api/generate-xmindmark" \
  -H "Content-Type: application/json" \
  -d '{"user_requirements": "T·∫°o mind map v·ªÅ AI", "stream": false}'
```

## Performance Optimization

### Concurrency
- **Parallel chunk processing**: ThreadPoolExecutor v·ªõi max 4 workers
- **Async streaming**: Real-time response processing
- **Model caching**: Whisper model singleton pattern

### Memory Management
- **Temporary files cleanup**: Auto-delete processed files
- **Streaming responses**: Reduce memory footprint
- **Content length limits**: Prevent OOM errors

### Caching Strategies
- **Model loading**: Load once, reuse multiple times
- **Search results**: Deduplicate similar queries
- **Generated content**: Store in session state

## Contributing

### Development Setup
1. Fork repository
2. Create feature branch
3. Install development dependencies
4. Run tests
5. Submit pull request

### Code Style
- **Python**: Follow PEP 8
- **FastAPI**: Use Pydantic models
- **Streamlit**: Component-based structure
- **Error Handling**: Comprehensive try-catch blocks

### Adding New Features
1. **New input source**: Add to `agent/utils/nodes.py`
2. **New LLM provider**: Extend `core/llm_provider.py`  
3. **New export format**: Add to `core/utils.py`
4. **New API endpoint**: Update `api/router.py`

## License

[Specify your license here]

## Support

- **Issues**: [GitHub Issues]
- **Documentation**: [Wiki/Docs link]
- **Email**: [Support email]

---

## üîÆ Roadmap

- [ ] **Multi-language support**: H·ªó tr·ª£ nhi·ªÅu ng√¥n ng·ªØ
- [ ] **Advanced templates**: Mind map templates c√≥ s·∫µn  
- [ ] **Collaboration**: Real-time collaborative editing
- [ ] **Mobile app**: React Native/Flutter app
- [ ] **Cloud storage**: Integration v·ªõi Google Drive/OneDrive
- [ ] **Advanced analytics**: Mind map usage statistics